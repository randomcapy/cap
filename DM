prac1--

# Load required libraries
install.packages("readr")
install.packages("GGally")
library(readr)
library(GGally)
library(dplyr)

# Load the dataset
toyota <- read.csv("ToyotaCorolla.csv")
View(toyota)
# Select relevant numeric columns for correlation matrix
numeric_vars <- toyota[, c("price", "age_08_04", "km", "hp", "weight", "cc")]

# Plot matrix
ggpairs(numeric_vars)

# Convert categorical variables into dummy variables
toyota_dummies <- toyota %>%
  mutate(
    Fuel_Type = as.factor(fuel_type),
    Metallic = as.factor(metallic_rim)
  ) %>%
# Create dummy variables
model.matrix(~ fuel_type + metallic_rim - 1, data = .) %>%
  as.data.frame() %>%
# Combine with original dataset (excluding original categorical vars)
bind_cols(toyota %>% select(-fuel_type, -metallic_rim), .)

# View the updated dataset
head(toyota_dummies)


PRAC2--

library(readr)
library(dplyr)
library(ggplot2)
install.packages("lubridate")
library(lubridate)
install.packages("zoo")
library(zoo)

# Load the dataset
data <- read.csv("ApplianceShipments.csv")
View(data)

# Convert Quarter to Date format
data$Date <- as.yearqtr(data$Quarter, format = "Q%q-%Y")
data$Year <- year(data$Date)
data$Qtr <- quarter(data$Date, with_year = FALSE)

# i. Time Plot
ggplot(data, aes(x = Date, y = Shipments)) +
  geom_line(color = "steelblue") +
  labs(title = "Quarterly Appliance Shipments", y = "Shipments ($M)", x = "Time")

# ii. Zoomed plot
ggplot(data, aes(x = Date, y = Shipments)) +
  geom_line(color = "tomato") +
  coord_cartesian(ylim = c(3500, 5000)) +
  geom_label(aes(label=Quarter,color =Quarter),show.legend = FALSE)+ 
  labs(title = "Zoomed Quarterly Appliance Shipments", y = "Shipments ($M)", x = "Time")

# iii. Separate lines by Quarter
ggplot(data, aes(x = Year, y = Shipments, color = as.factor(Qtr))) +
  geom_line() +
  facet_wrap(~Qtr, ncol = 1) +
  coord_cartesian(ylim = c(3500, 5000)) +
  labs(title = "Shipments by Quarter", y = "Shipments ($M)", color = "Quarter")

# iv. Yearly Aggregated Line Graph
yearly_data <- data %>%
  group_by(Year) %>%
  summarise(YearlyTotal = sum(Shipments))

ggplot(yearly_data, aes(x = Year, y = YearlyTotal)) +
  geom_line(color = "darkgreen") +
  labs(title = "Yearly Total Appliance Shipments", y = "Total Shipments ($M)")


PRAC3---

# Load the dataset
ToyotaCorolla <- read.csv("ToyotaCorolla.csv")
View(ToyotaCorolla)
# i. Identify the categorical variables
# Assuming categorical variables are those with character or factor data type

ToyotaCorolla$Fuel_Type <- factor(ToyotaCorolla$fuel_type)
unique(ToyotaCorolla$fuel_type)
categorical_vars <- sapply(ToyotaCorolla, is.factor)
categorical_vars

# ii. Explain the relationship between a categorical variable and
the series of binary dummy variables derived from it
##A categorical variable represents different categories or
groups, such as colors, types of cars, or levels of education
##Dummy variables are binary variables created to represent
the categories of a categorical variable.
##Each dummy variable corresponds to one category of the
categorical variable.
# Dummy variables are binary variables created to represent
the categories of a categorical variable.
# Each dummy variable corresponds to one category of the
categorical variable, with a value of 1 indicating presence and 0
indicating absence.
# iii. How many dummy binary variables are required to capture
the information in a categorical variable with N categories?
  # For a categorical variable with N categories, N-1 dummy
  variables are needed. This is to avoid perfect multicollinearity.
# iv. Convert categorical variables into dummy binaries

ToyotaCorolla$Fuel_Type <- factor(ToyotaCorolla$fuel_type)

# Create dummy variables for Fuel_Type
dummy_vars <- model.matrix(~ fuel_type - 1, data =ToyotaCorolla)
# Attach the dummy variables to the dataset
ToyotaCorolla <- cbind(ToyotaCorolla, dummy_vars)

# Optionally, you can remove the original Fuel_Type column if it's no longer needed
ToyotaCorolla <- ToyotaCorolla[, !(names(ToyotaCorolla) %in% "fuel_type")]

View(ToyotaCorolla)


PRAC4 ---


install.packages("FNN")
library(FNN)
housing.df <- read.csv("BostonHousing.csv")
set.seed(123)
train.index <- sample(row.names(housing.df),
                      0.6*dim(housing.df)[1])
valid.index <- setdiff(row.names(housing.df), train.index)
train.df <- housing.df[train.index, -14]
valid.df <- housing.df[valid.index, -14]

# initialize normalized training, validation data, complete data frames to originals
train.norm.df <- train.df
valid.norm.df <- valid.df
housing.norm.df <-housing.df
# use preProcess() from the caret package to normalize Income and Lot_Size.
install.packages("caret")
library(caret)
norm.values <- preProcess(train.df, method=c("center","scale"))
train.norm.df <- as.data.frame(predict(norm.values, train.df))
valid.norm.df <- as.data.frame(predict(norm.values, valid.df))
housing.norm.df <- as.data.frame(predict(norm.values,housing.df))

#initialize a data frame with two columns: k, and accuracy
accuracy.df <- data.frame(k = seq(1, 5, 1), RMSE = rep(0, 5))
# compute knn for different k on validation.
for(i in 1:5){
  knn.pred<-class::knn(train = train.norm.df[,-13],
                       test = valid.norm.df[,-13],
                       cl = train.df[,13], k = i)
  accuracy.df[i,2]<-
    RMSE(as.numeric(as.character(knn.pred)),valid.df[,13])
}
accuracy.df

Part B
#Predict the MEDV for a tract with the following information,using the best k:
new.df<- data.frame(
  CRIM = 0.2, ZN = 0, INDUS = 7, CHAS = 0, NOX = 0.538,
  RM = 6, AGE = 62, DIS = 4.7, RAD = 4, TAX = 307,
  PTRATIO = 21, B = 360, LSTAT = 10
)
new.norm.values <- preProcess(new.df, method=c("center","scale"))
new.norm.df <- predict(new.norm.values, newdata = new.df)
#predict the MEDV
new.knn.pred <-class::knn(train = train.norm.df[,-13],
                           test = new.norm.df,
                           cl =train.df$MEDV, k = 2)
new.knn.pred
new.accuracy.df<-RMSE(as.numeric(as.character(new.knn.pred)),valid.df[,13])
new.accuracy.df



PRAC5----

library(dplyr)
accidents.df <- read.csv("AccidentsFull.csv")
View(accidents.df)
accidents.df$INJURY <- ifelse(accidents.df$MAX_SEV_IR>0,
                              "yes", "no")
head(accidents.df)

#Part A
#create a table based on INJURY
inj.tbl <- table(accidents.df$INJURY)
show(inj.tbl)
#caluculate probability of injury
inj.prob = scales::percent(inj.tbl["yes"]/(inj.tbl["yes"]+inj.tbl["no"]),0.01)
inj.prob
#Ans: Since ~51% of the accidents in our data set resulted in an accident, we should predict that an accident will result in injury because it is slightly more likely.

#Part B
#convert your variables to categorical type
for (i in c(1:dim(accidents.df)[2])){
  accidents.df[,i] <- as.factor(accidents.df[,i])
}
#create a new subset with only the required records
new.df <- accidents.df[1:12,
                       c("INJURY","WEATHER_R","TRAF_CON_R")]
new.df
#B i
#Load library for pivot table
install.packages("rpivotTable")
library(rpivotTable)
rpivotTable::rpivotTable(new.df)
#B.ii
#Compute the exact Bayes conditional probabilities of an injury (INJURY = Yes) given the six possible combinations of the predictors.
#To find P(Injury=yes|WEATHER_R = 1, TRAF_CON_R =0):
numerator1 <- 2/3 * 3/12
denominator1 <- 3/12
prob1 <- numerator1/denominator1
prob1
#To find P(Injury=yes|WEATHER_R = 1, TRAF_CON_R =1):
numerator2 <- 0 * 3/12
denominator2 <- 1/12
prob2 <- numerator2/denominator2
prob2
#To find P(Injury=yes| WEATHER_R = 1, TRAF_CON_R =2):
numerator3 <- 0 * 3/12
denominator3 <- 1/12
prob3 <- numerator3/denominator3
prob3
#To find P(Injury=yes| WEATHER_R = 2, TRAF_CON_R =0):
numerator4 <- 1/3 * 3/12
denominator4 <- 6/12
prob4 <- numerator4/denominator4
prob4
#To find P(Injury=yes| WEATHER_R = 2, TRAF_CON_R =1):
numerator5 <- 0 * 3/12
denominator5 <- 1/12
prob5 <- numerator5/denominator5
prob5
#To find P(Injury=yes| WEATHER_R = 2, TRAF_CON_R =2):
numerator6 <- 0 * 3/12
denominator6 <- 0
prob6 <- numerator6/denominator6
prob6
a<-c(1,2,3,4,5,6)
b<-c(prob1,prob2,prob3,prob4,prob5,prob6)
prob.df<-data.frame(a,b)
names(prob.df)<-c('Option #','Probability')
prob.df %>% mutate_if(is.numeric, round, 3)
#NOTE: In the above 12 observations there is no observation with (Injury=yes, WEATHER_R = 2, TRAF_CON_R =2). The conditional probability here is undefined, since the denominator is zero.
#B.iii Classify the 12 accidents using these probabilities and a cutoff of 0.5.
#add probability results to you subset
new.df.prob<-new.df
head(new.df.prob)
prob.inj <- c(0.667, 0.167, 0, 0, 0.667, 0.167, 0.167, 0.667,
              0.167, 0.167,
              0.167, 0)
new.df.prob$PROB_INJURY<-prob.inj
#add a column for injury prediction based on a cutoff of 0.5
new.df.prob$PREDICT_PROB<-
  ifelse(new.df.prob$PROB_INJURY>.5,"yes","no")
new.df.prob
#B.iv
man.prob <- 2/3 * 0/3 * 3/12
man.prob
#B.v
install.packages("e1071")
library(e1071)
install.packages("klaR")
library(klaR)
library(caret)
library(ggplot2)
library(lattice)
nb<-naiveBayes(INJURY ~ ., data = new.df)
predict(nb, newdata = new.df,type = "raw")
x=new.df[,-3]
y=new.df$INJURY
model <- train(x,y,'nb', trControl = trainControl(method ='cv',number=10))
model
#Now that we have generated a classification model, we use it for prediction
model.pred<-predict(model$finalModel,x)
model.pred
##build a confusion matrix so that we can visualize the classification errors
table(model.pred$class,y)
#compare against the manually calculated results
new.df.prob$PREDICT_PROB_NB<-model.pred$class
new.df.prob

#Part c
#Let us now return to the entire dataset. Partition the data into training (60%) and validation (40%).
set.seed(22)
train.index <- sample(c(1:dim(accidents.df)[1]),
                      dim(accidents.df)[1]*0.6)
train.df <- accidents.df[train.index,]
valid.df <- accidents.df[-train.index,]

#C.i
#We can use the predictors that describe the calendar time or road
#conditions: HOUR_I_R ALIGN_I WRK_ZONE WKDY_I_R INT
#_HWY LGTCON_I_R PROFIL_I_R SPD_LIM SUR_CON TRAF
#_CON_R TRAF_WAY WEATHER_R

#C.ii
#define which variable you will be using
vars <- c("INJURY", "HOUR_I_R", "ALIGN_I" ,"WRK_ZONE",
          "WKDY_I_R",
          "INT_HWY", "LGTCON_I_R", "PROFIL_I_R",
          "SPD_LIM", "SUR_COND",
          "TRAF_CON_R", "TRAF_WAY", "WEATHER_R")
nbTotal <- naiveBayes(INJURY ~ ., data = train.df[,vars])
#generate the confusion matrix using the train.df, the prediction and the classes
confusionMatrix(train.df$INJURY, predict(nbTotal, train.df[,vars]), positive = "yes")
ner=1-.5384
nerp=scales::percent(ner,0.01)
nerp

#C.iii What is the overall error for the validation set?
confusionMatrix(valid.df$INJURY, predict(nbTotal, valid.df[,vars]),positive = "yes")
ver=1-.5354
verp=scales::percent(ver,0.01)
paste("Overall Error: ",verp)

#C.iv What is the percent improvement relative to the naive rule (using the validation set)?
imp=ver-ner
paste("The percent improvement is ",scales::percent(imp,0.01))

#C.v Examine the conditional probabilities output. Why do we get a probability of zero for P(INJURY = No j SPD_LIM = 5)?
options(digits = 2)
nbTotal



PRAC6----


library(dplyr)
library(caret)
install.packages("tidyverse")
library(tidyverse)
Toyotacorolla <- read.csv("ToyotaCorolla.csv")
View(Toyotacorolla)
Toyotacorolla1 <- Toyotacorolla[,c(
  "price", "age_08_04", "km", "fuel_type", "hp", "automatic",
  "doors", "quarterly_tax","mfr_guarantee",
  "guarantee_period",
  "airco", "automatic_airco", "cd_player", "powered_windows",
  "sport_model", "tow_bar")]
#Converting Categorical Predictor to dummy variable using
#library fast dummies
install.packages("fastDummies")
library(fastDummies)
Toyotacorolla2 <- Toyotacorolla1 %>%
  dummy_cols(select_columns=c('fuel_type'))
#Removing original Fuel_Type and one of the dummy variables
#from the previous data frame
Toyotacorolla3 <- Toyotacorolla2 %>%
  dummy_cols(select_columns=c('fuel_type','fuel_type_CNG'))
#Removing NA values
Toyotacorolla3[is.na(Toyotacorolla3)]<-0

library(caret)
#Let's preprocess the data by scaling the numerical variables to a 0-1 scale using method="range"
data_normalize <- preProcess(Toyotacorolla3,
                             method=c("range"), na.remove=TRUE)
#The processed data is sent to predict() function to get the final normalized data using the min-max scaling method
data_normalize2 <-
  predict(data_normalize,as.data.frame(Toyotacorolla3))
#a. Fit a neural network model to the data. Use a single hidden layer with 2 nodes.
#Let's split the data into training (80%) and validation (20%)
ind <- sample(2, nrow(data_normalize2), replace=TRUE,
              prob=c(0.8, 0.2))
tdata <- data_normalize2[ind==1, ] #ind==1 means the firstsample
vdata<- data_normalize2[ind==2, ] #ind==2 means the second sample
#A. Fitting a neural network model to the data using a single hidden layer with 2 nodes.
#Plotting the neural network for training data
install.packages("fastDummies")
library(fastDummies)

# Convert categorical variables to dummies
tdata <- dummy_cols(tdata, remove_first_dummy = TRUE, remove_selected_columns = TRUE)

# Ensure all columns are numeric
str(tdata)
install.packages("neuralnet")
library(neuralnet)
nn <- neuralnet(data = tdata, price ~., hidden=2)
plot(nn, rep="best")
#Calculating RMSE on training data
pred <- compute(nn, tdata)$net.result
install.packages("Metrics")
library(Metrics)
Error <- RMSE(tdata[, "price"], pred)
#We use rmse() function from the Metrics package
Error
#Plotting the neural network for validation data
vdata <- dummy_cols(vdata, remove_first_dummy = TRUE, remove_selected_columns = TRUE)
nn <- neuralnet(data = vdata, price ~., hidden=2)
plot(nn, rep="best")
#Calculating RMSE on the validation data
pred <- compute(nn, vdata)$net.result
error <-RMSE(vdata[, "price"], pred) #We use rmse() function from the Metrics package
error

#B. Fitting a neural network model to the data using single layer with 5 nodes
#Plotting the neural network for training data
nn <- neuralnet(data = tdata, price ~., hidden=c(5)) #5 nodes, 1 layers
plot(nn, rep="best")
#Calculating RMSE on training data
pred <- compute(nn, tdata)$net.result
error <- RMSE(tdata[, "price"], pred) #We use rmse() function from the Metrics package
error
#Plotting the neural network for validation data
nn <- neuralnet(data = vdata, price ~., hidden=c(5)) # 5 nodes,1 layers
plot(nn,rep="best")
#Calculating RMSE on validation data
pred <- compute(nn, vdata)$net.result
error <- RMSE(vdata[, "price"], pred) #We use rmse() function from the Metrics package
error

#C. Fitting a neural network model to the data using two layer with 5 nodes in eack layer
#Plotting the neural network for training data
nn <- neuralnet(data = tdata, price ~., hidden=c(5,5)) #5 nodes, 2 layers
plot(nn, rep="best")
#Calculating RMSE on training data
pred <- compute(nn, tdata)$net.result
error <- RMSE(tdata[, "price"], pred) #We use rmse() function from the Metrics package
error
#Plotting the neural network for validation data
nn <- neuralnet(data = vdata, price ~., hidden=c(5,5)) # 5 nodes,2 layers
plot(nn,rep="best")
#Calculating RMSE on validation data
pred <- compute(nn, vdata)$net.result
error <- RMSE(vdata[, "price"], pred) #We use rmse() function from the Metrics package
error
#i. What happens to the RMS error for the training data as the number of layers and nodes increases?
#We can see from the above outputs that the root mean square
#error for the training data decreases as we increase the number of layers and nodes.
#ii. What happens to the RMS error for the validation data?
#We can see from the above outputs that the root mean square error for the validation data increases.
#iii. Comment on the appropriate number of layers and nodes for this application.
#From the above results, we can conclude that 2 layers and 5 nodes in each layer are appropriate for this application.




PRAC7------


# Load required libraries
install.packages("arules")
install.packages("arulesViz")
library(arules)
library(arulesViz)

# Load the dataset
data <- read.transactions("Coursetopics.csv", format = "basket", sep = ",")

summary(data)
itemFrequencyPlot(data, topN = 10, type = "absolute", main = "Top 10 Course Topics")

rules <- apriori(data, 
                 parameter = list(supp = 0.05, conf = 0.6, minlen = 2))

# Basic visualization
plot(rules, method = "graph", engine = "htmlwidget")

plot(rules, method = "grouped")
plot(rules, method = "matrix", measure = c("support", "confidence"))



PRAC 8-------


library(readr ) 
install.packages("forecast") 
library(forecast) 
wallmart <- read.csv("WMT.csv") 
View(wallmart)  
#Create a time plot of the differenced series. 
library(stats) 
closing_prices <- wallmart$Close 
closing_prices
diff_series <- diff(closing_prices) 
diff_series
png("acf_plot.png", width = 800, height = 600)
acf(closing_prices, main = "Autocorrelation of Close Prices Series")
dev.off()
plot(diff_series, type = "l", xlab = "Time", ylab = "Differenced 
Closing Prices",  main = "Time Plot of Differenced Series") 
#II. Which of the following is/are relevant for testing whether 
#a. The autocorrelations of the close prices series  
acf(closing_prices, main = "Autocorrelation of Close Prices 
Series") 
#Significant autocorrelations at higher lags may indicate non
#b. The AR(1) slope coefficient  
closing_prices <- arima.sim(n=100, list(ar=0.7)) 
ar_model <- arima(closing_prices, order = c(1, 0, 0)) 
summary(ar_model) 
Output: 
Call:
arima(x = closing_prices, order = c(1, 0, 0))

Coefficients:
         ar1  intercept
      0.5367    -0.0812
s.e.  0.0858     0.2096

sigma^2 estimated as 0.9616:  log likelihood = -140.1,  aic = 286.21

Training set error measures:
                     ME      RMSE       MAE      MPE     MAPE      MASE       ACF1
Training set 0.01064423 0.9805992 0.7823038 109.9737 125.8984 0.8871688 0.03589863





PRAC 9--------

library(readr)
install.packages("forecast")
library(forecast)
wallmart <- read.csv("WMT.csv")
View(wallmart)
#I. Create a time plot of the differenced series.
library(stats)
closing_prices <- wallmart$Close
diff_series <- diff(closing_prices)
plot(diff_series, type = "l", xlab = "Time", ylab = "Differenced Closing Prices",main = "Time Plot of Differenced Series")
#II. Which of the following is/are relevant for testing whether this stock is a random walk?
#a. The autocorrelations of the close prices series
acf(closing_prices, main = "Autocorrelation of Close Prices Series")
#Significant autocorrelations at higher lags may indicate nonrandom behavior.
#b. The AR(1) slope coefficient
closing_prices <- arima.sim(n=100, list(ar=0.7))
ar_model <- arima(closing_prices, order = c(1, 0, 0))
summary(ar_model)
ar_model$coef[1]
#C The AR(1) constant coefficient
ar_model <- arima(closing_prices, order = c(1, 0, 0))
summary(ar_model)
ar_model$coef[2]

Question | Correct Answer(s)
ii | a, b
iv | c



PRAC 10 ---------



#Create a well-formatted time plot of the data
# Load necessary libraries
library(ggplot2)
library(readr)
library(lubridate)

# Read data
data <- read.csv("SouvenirSales.csv")
View(data)
library(zoo)
colnames(data)[1] <- "Month"
head(data$Month)
data$Month <- as.yearmon(data$Month, format = "%b-%y")
data$Month <- as.Date(data$Month)

# Time plot of original data
ggplot(data, aes(x = Month, y = Sales)) +
  geom_line(color = "blue") +
  labs(title = "Monthly Souvenir Sales (1995–2001)",
       x = "Month", y = "Sales") +
  theme_minimal()

#ii. Apply log scale to achieve linearity
# Time plot with log(y-axis)
ggplot(data, aes(x = Month, y = log(Sales))) +
  geom_line(color = "darkgreen") +
  labs(title = "Log-Transformed Monthly Souvenir Sales",
       x = "Month", y = "Log(Sales)") +
  theme_minimal()

#iii. Type of trend in the data?
#The original time plot shows a non-linear, exponential upward trend.
#The log-transformed plot reveals a linear trend.

#iv. Why were the data partitioned?
#Purpose of partitioning:
#To train the model on historical data and test its forecasting performance on unseen data (validation set).
#Prevents overfitting and ensures that forecasts generalize well.

#Partitioning the data (1995–2000: training, 2001: validation)
# Split data into training and validation sets
training <- subset(data, year(Month) < 2001)
validation <- subset(data, year(Month) == 2001)

# Check sizes
nrow(training)  # Should be 72 months
nrow(validation)  # Should be 12 months
